{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04459908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a318a56f",
   "metadata": {},
   "source": [
    "# Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a401a702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2, 2. , 3. , 5. ])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data_each_env = 1500\n",
    "E = np.array([0.4,0.6,0.8,1.1,1.5,1.8,2.3,2.8])\n",
    "E = np.array([0.2, 2, 3, 5])\n",
    "E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f550a8cc",
   "metadata": {},
   "source": [
    "# ICARL Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9d1810ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim,hidden_dim)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim,output_dim)\n",
    "    def forward(self, x):\n",
    "        y = self.fc1(x)\n",
    "        y = self.act1(y)\n",
    "        y = self.fc2(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "78110549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_function(mode=\"mlp\"):\n",
    "    if mode==\"mlp\":\n",
    "        return MLP(2, 16, 10).to(torch.float64)\n",
    "    elif mode==\"identity\":\n",
    "        return lambda z: z\n",
    "\n",
    "non_linearity_type = \"neural_network\"\n",
    "\n",
    "# non_linearity = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5e06cdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "S1 = list()\n",
    "S2 = list()\n",
    "Y = list()\n",
    "X = list()\n",
    "U = list()\n",
    "\n",
    "non_linearity = MLP(2, 12, 10).to(torch.float64)\n",
    "\n",
    "for e in E:\n",
    "    S1_env = np.random.normal(e, 1, num_data_each_env)\n",
    "    S2_env = np.random.normal(2*e, 2, num_data_each_env)\n",
    "\n",
    "    S1_env_t = torch.tensor(S1_env).unsqueeze(dim=1)\n",
    "    S2_env_t = torch.tensor(S2_env).unsqueeze(dim=1)\n",
    "\n",
    "    S1_S2_env_t = torch.cat([S1_env_t, S2_env_t], dim=1)\n",
    "    \n",
    "    Y_mu_env = S1_env + S2_env\n",
    "    \n",
    "    S1.append( S1_env )\n",
    "    S2.append( S2_env )\n",
    "    \n",
    "    Y.append( \n",
    "        np.random.normal( S1_env+S2_env, 1, num_data_each_env)\n",
    "    )\n",
    "    \n",
    "    X.append(\n",
    "        non_linearity(\n",
    "            S1_S2_env_t\n",
    "        ).detach().numpy()\n",
    "    )\n",
    "    \n",
    "    U.append(\n",
    "        e * np.ones(num_data_each_env)\n",
    "    )\n",
    "    \n",
    "#     X_env.append(\n",
    "#             non_linearity(\n",
    "#                 torch.\n",
    "#             )\n",
    "#     )\n",
    "    \n",
    "#     Y_env = list()\n",
    "#     X_env = list()\n",
    "#     for (z_1, z_2) in zip(Z1_env, Z2_env):\n",
    "#         Y_env.append(np.random.normal(z_1+z_2, 1, 1)[0]) \n",
    "#         _input = torch.tensor([[z_1, z_2]])\n",
    "#         X_env.append( non_linearity(_input)[0,:].detach().numpy() )\n",
    "    \n",
    "#     Z1.append(Z1_env)\n",
    "#     Z2.append(Z2_env)\n",
    "#     Y.append(Y_env)\n",
    "#     X.append(X_env)\n",
    "#     U.append([e]*num_data_each_env)\n",
    "\n",
    "S1 = np.array(Z1)[:, :, np.newaxis]\n",
    "S2 = np.array(Z2)[:, :, np.newaxis]\n",
    "S = np.concatenate([S1, S2], axis=2).squeeze()\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)[:, :, np.newaxis]\n",
    "U = np.array(U)[:, :, np.newaxis]\n",
    "U = np.concatenate([U, Y], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e115e926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘icarl_data’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir \"icarl_data\"\n",
    "\n",
    "np.save(f\"./icarl_data/x.npy\", X)\n",
    "np.save(f\"./icarl_data/u.npy\", U)\n",
    "np.save(f\"./icarl_data/s.npy\", S)\n",
    "\n",
    "!cp \"./icarl_data/x.npy\" \"./run/datasets/x.npy\"\n",
    "!cp \"./icarl_data/u.npy\" \"./run/datasets/u.npy\"\n",
    "!cp \"./icarl_data/s.npy\" \"./run/datasets/s.npy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb7c694",
   "metadata": {},
   "source": [
    "# Load the Data with ICARL Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fccbc452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data' from '/home/mlcmadmin/ahedayat/causal_ivae/data/__init__.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import data\n",
    "\n",
    "import importlib\n",
    "importlib.reload(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3ea891a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (6000, 10)\n",
      "U: (6000, 2)\n",
      "S: (6000, 2)\n"
     ]
    }
   ],
   "source": [
    "dataset = data.ICARLDataset(\n",
    "    root=\"./run/datasets\", \n",
    "    data_postfix=\"\",\n",
    ")\n",
    "\n",
    "print(f\"X: {dataset.x.shape}\")\n",
    "print(f\"U: {dataset.u.shape}\")\n",
    "print(f\"S: {dataset.s.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ece78d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, u, s = dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25847f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd1b2ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fb8930c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55251ba6",
   "metadata": {},
   "source": [
    "# Non-Linear Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff40b474",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_each_env = 1500\n",
    "E = np.array([0.4,0.6,0.8,1.1,1.5,1.8,2.3,2.8])\n",
    "E = np.array([0.2, 2, 3, 5])\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354fac38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18974274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7128108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5203024b",
   "metadata": {},
   "source": [
    "# Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "baf40ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalerZ = MinMaxScaler()\n",
    "# scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8bfd4077",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z1 = list()\n",
    "Z2 = list()\n",
    "Z3 = list()\n",
    "Z4 = list()\n",
    "Z5 = list()\n",
    "Y = list()\n",
    "# Y2 = list()\n",
    "X = list()\n",
    "U = list()\n",
    "\n",
    "non_linearity = MLP().to(torch.float64)\n",
    "\n",
    "for e in E:\n",
    "    Z1_env = np.random.normal(e, 1, num_data_each_env)\n",
    "    Z2_env = np.random.normal(2*e, 2, num_data_each_env)\n",
    "    \n",
    "    L13_env = np.random.uniform(1.2*e , 1.8*e)\n",
    "    L24_env = np.random.normal(1.5*e ,2.5*e)\n",
    "    L35_env = np.random.uniform(1.6*e , 2.6*e)\n",
    "    Ly5_env = np.random.uniform(1.2*e , 2.3*e)\n",
    "    Z3_env = np.random.normal(1.75*e, 1, num_data_each_env) + L13_env * Z1_env**2 + Z1_env\n",
    "    Z4_env = np.random.normal(1.2*e, 2, num_data_each_env) + L24_env * Z2_env**2 + Z2_env\n",
    "#     Z5_env = np.random.normal(4*e, 2, num_data_each_env) + L24_env * Z2_env**2\n",
    "\n",
    "    Z5_env = list()\n",
    "    Y_env = list()\n",
    "    X_env = list()\n",
    "    for (z_1, z_2 , z_3 , z_4) in zip(Z1_env, Z2_env ,Z3_env, Z4_env):\n",
    "        y_tmp = np.random.normal(z_4 + z_2 , 1, 1)[0]\n",
    "        Y_env.append(y_tmp) \n",
    "        z5_tmp = Ly5_env*y_tmp + L35_env*(z_3) + np.random.normal(0.2*e, 2, 1)[0]\n",
    "        _input = torch.tensor([[z_1, z_2,z_3 , z_4 , z5_tmp]])\n",
    "        X_env.append( non_linearity(_input)[0,:].detach().numpy() )\n",
    "        Z5_env.append(z5_tmp)\n",
    "    \n",
    "    Z1.append(Z1_env)\n",
    "    Z2.append(Z2_env)\n",
    "    Z3.append(Z1_env)\n",
    "    Z4.append(Z2_env)\n",
    "    Z5.append(Z5_env)\n",
    "    Y.append(Y_env)\n",
    "    X.append(X_env)\n",
    "    U.append([e]*num_data_each_env)\n",
    "\n",
    "Z1 = np.array(Z1)\n",
    "Z2 = np.array(Z2)\n",
    "Z3 = np.array(Z3)\n",
    "Z4 = np.array(Z4)\n",
    "Z5 = np.array(Z5)\n",
    "Y = np.array(Y)\n",
    "X = np.array(X)\n",
    "U = np.array(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "fed2e453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z1 = list()\n",
    "# Z2 = list()\n",
    "# Z3 = list()\n",
    "# Z4 = list()\n",
    "# Y = list()\n",
    "# X = list()\n",
    "# U = list()\n",
    "\n",
    "# non_linearity = MLP().to(torch.float64)\n",
    "\n",
    "# for e in E:\n",
    "#     Z1_env = np.random.normal(e, 1, num_data_each_env)\n",
    "#     Z2_env = np.random.normal(2*e, 2, num_data_each_env)\n",
    "#     L13_env = np.random.uniform(3.7*e , 8*e)\n",
    "#     L24_env = np.random.normal(2.5*e ,9*e)\n",
    "#     Z3_env = np.random.normal(3*e, 1, num_data_each_env) + L13_env * (Z1_env ** 2)\n",
    "#     Z4_env = np.random.normal(4*e, 2, num_data_each_env) + L24_env * (Z2_env ** 2)\n",
    "\n",
    "    \n",
    "#     Y_env = list()\n",
    "#     X_env = list()\n",
    "#     for (z_1, z_2 , z_3 , z_4) in zip(Z1_env, Z2_env ,Z3_env, Z4_env):\n",
    "#         Y_env.append(np.random.normal(z_1+z_2 , 1, 1)[0]) \n",
    "#         _input = torch.tensor([[z_1, z_2,z_3 , z_4]])\n",
    "#         X_env.append( non_linearity(_input)[0,:].detach().numpy() )\n",
    "    \n",
    "#     Z1.append(Z1_env)\n",
    "#     Z2.append(Z2_env)\n",
    "#     Z3.append(Z1_env)\n",
    "#     Z4.append(Z2_env)\n",
    "#     Y.append(Y_env)\n",
    "#     X.append(X_env)\n",
    "#     U.append([e]*num_data_each_env)\n",
    "\n",
    "# Z1 = np.array(Z1)\n",
    "# Z2 = np.array(Z2)\n",
    "# Z3 = np.array(Z3)\n",
    "# Z4 = np.array(Z4)\n",
    "# Y = np.array(Y)\n",
    "# X = np.array(X)\n",
    "# U = np.array(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "2e39b0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.concatenate([X[env, :, :] for env in range(X.shape[0])])\n",
    "# Y = np.concatenate([Y[env, :] for env in range(Y.shape[0])])\n",
    "# Y = Y[:, np.newaxis]\n",
    "\n",
    "# Z1 = np.concatenate([Z1[env, :] for env in range(Z1.shape[0])])\n",
    "# Z2 = np.concatenate([Z2[env, :] for env in range(Z2.shape[0])])\n",
    "\n",
    "# Z1 = Z1[:, np.newaxis]\n",
    "# Z2 = Z2[:, np.newaxis]\n",
    "# Z = np.concatenate([Z1, Z2], axis=1)\n",
    "\n",
    "# U = np.concatenate([U[env, :] for env in range(U.shape[0])])\n",
    "# U = U[:, np.newaxis]\n",
    "# U = np.concatenate([U, Y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb6b512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4ea1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad42119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "745808d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([X[env, :, :] for env in range(X.shape[0])])\n",
    "Y = np.concatenate([Y[env, :] for env in range(Y.shape[0])])\n",
    "Y = Y[:, np.newaxis]\n",
    "\n",
    "Z1 = np.concatenate([Z1[env, :] for env in range(Z1.shape[0])])\n",
    "Z2 = np.concatenate([Z2[env, :] for env in range(Z2.shape[0])])\n",
    "Z3 = np.concatenate([Z3[env, :] for env in range(Z3.shape[0])])\n",
    "Z4 = np.concatenate([Z4[env, :] for env in range(Z4.shape[0])])\n",
    "Z5 = np.concatenate([Z5[env, :] for env in range(Z5.shape[0])])\n",
    "\n",
    "Z1 = Z1[:, np.newaxis]\n",
    "Z2 = Z2[:, np.newaxis]\n",
    "Z3= Z3[:, np.newaxis]\n",
    "Z4 = Z4[:, np.newaxis]\n",
    "Z5 = Z5[:, np.newaxis]\n",
    "Z = np.concatenate([Z1, Z2 , Z3 , Z4, Z5], axis=1)\n",
    "\n",
    "U = np.concatenate([U[env, :] for env in range(U.shape[0])])\n",
    "U = U[:, np.newaxis]\n",
    "U = np.concatenate([U, Y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "68cd28e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f48ead9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 5)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f462218d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "68270762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 12)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4364ea03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# colors = [\"red\", \"blue\", \"yellow\", \"black\"]\n",
    "\n",
    "for ix, e in enumerate(E):\n",
    "    start_index = num_data_each_env*ix\n",
    "    end_index = num_data_each_env*(ix+1) - 1\n",
    "    plt.scatter(Z[start_index:end_index, 1], Z[start_index:end_index, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c15fbfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints  datasets  datasets_synthetic_data\tivae_0_1.p  logs\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./running_related_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "68998bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./run/synthetic_datasets’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"./run/synthetic_datasets\"\n",
    "!mkdir $dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5c1c9bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"{dataset_path}/x_nl_5node1.npy\", X)\n",
    "np.save(f\"{dataset_path}/y_nl_5node1.npy\", Y)\n",
    "np.save(f\"{dataset_path}/s_nl_5node1.npy\", Z)\n",
    "np.save(f\"{dataset_path}/u_nl_5node1.npy\", U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4e6d1680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([919.04687471])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "93d127c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "for i in range(3):\n",
    "    other_features = [j for j in range(3) if j!=i]\n",
    "    \n",
    "    for j in other_features:\n",
    "        pairs.append((i,j))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e365a7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = pairs[1]\n",
    "\n",
    "f1 = torch.Tensor(Z[:,pair[0]:pair[0]+1])\n",
    "f2 = torch.Tensor(Z[:,pair[1]:pair[1]+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "48c8aab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_f1 = torch.Tensor([pair[0] for i in range(f1.shape[0])])\n",
    "index_f1 = index_f1[:,None]\n",
    "index_f2 = torch.Tensor([pair[1] for i in range(f1.shape[0])])\n",
    "index_f2 = index_f2[:,None]\n",
    "zn = torch.cat((f1,f2,index_f1 , index_f2), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "1d280a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4000, 4])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "dce8ae6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4000, 1])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "5f2035d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  name\n",
       " 0  ali,\n",
       "     name\n",
       " 0  mehdi)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.DataFrame({\"name\": [\"ali\"]})\n",
    "df2 = pd.DataFrame({\"name\": [\"mehdi\"]})\n",
    "df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "640990d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mehdi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mehdi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mehdi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name\n",
       "0    ali\n",
       "0  mehdi\n",
       "0  mehdi\n",
       "0  mehdi"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 =pd.concat([df1, df2])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "3e78c37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import cleanIVAE, cleanVAE, Discriminator, MLP, CIVAE, permute_dims\n",
    "def get_model(data_dim, env_dim, latent_dim, config):\n",
    "\n",
    "    # Data Encoder\n",
    "    data_encoder = MLP(\n",
    "        input_dim = data_dim,\n",
    "        output_dim = config.data_enc_output_dim,\n",
    "        hidden_dim = config.data_enc_hidden_dim,\n",
    "        n_layers = config.data_enc_n_layers,\n",
    "        activation = config.data_enc_activation,\n",
    "        slope = config.data_enc_slope\n",
    "    ).to(torch.float64).to(config.device)\n",
    "    \n",
    "    # Environment Encoder\n",
    "    env_encoder = MLP(\n",
    "        input_dim = env_dim,\n",
    "        output_dim = config.env_enc_output_dim,\n",
    "        hidden_dim = config.env_enc_hidden_dim,\n",
    "        n_layers = config.env_enc_n_layers,\n",
    "        activation = config.env_enc_activation,\n",
    "        slope = config.env_enc_slope\n",
    "    ).to(torch.float64).to(config.device)\n",
    "\n",
    "    # Linear Prior \n",
    "    linear_prior = MLP(\n",
    "        input_dim = config.data_enc_output_dim,\n",
    "        output_dim = config.data_enc_output_dim,\n",
    "        hidden_dim = config.linear_prior_hidden_dim,\n",
    "        n_layers = config.linear_prior_n_layers,\n",
    "        activation = config.linear_prior_activation,\n",
    "        slope = config.linear_prior_slope\n",
    "    ).to(torch.float64).to(config.device)\n",
    "\n",
    "    # Linear Prior's Environment Encoder \n",
    "    env_encoder_linear_prior = MLP(\n",
    "        input_dim = env_dim,\n",
    "        output_dim = config.data_enc_output_dim,\n",
    "        hidden_dim = config.env_encoder_linear_prior_hidden_dim,\n",
    "        n_layers = config.env_encoder_linear_prior_n_layers,\n",
    "        activation = config.env_encoder_linear_prior_activation,\n",
    "        slope = config.env_encoder_linear_prior_slope\n",
    "    ).to(torch.float64).to(config.device)\n",
    "\n",
    "    # Non-Linear Prior \n",
    "    non_linear_prior = MLP(\n",
    "        input_dim = config.data_enc_output_dim,\n",
    "        output_dim = config.data_enc_output_dim,\n",
    "        hidden_dim = config.non_linear_prior_hidden_dim,\n",
    "        n_layers = config.non_linear_prior_n_layers,\n",
    "        activation = config.non_linear_prior_activation,\n",
    "        slope = config.non_linear_prior_slope\n",
    "    ).to(torch.float64).to(config.device)\n",
    "\n",
    "    # Non-Linear Prior Environment Encoder \n",
    "    env_encoder_non_linear_prior = MLP(\n",
    "        input_dim = env_dim,\n",
    "        output_dim = config.data_enc_output_dim,\n",
    "        hidden_dim = config.env_encoder_non_linear_prior_hidden_dim,\n",
    "        n_layers = config.env_encoder_non_linear_prior_n_layers,\n",
    "        activation = config.env_encoder_non_linear_prior_activation,\n",
    "        slope = config.env_encoder_non_linear_prior_slope\n",
    "    ).to(torch.float64).to(config.device)\n",
    "\n",
    "    # Graph Weights\n",
    "    graph_weights = MLP(\n",
    "        input_dim = env_dim,\n",
    "        output_dim = latent_dim * (latent_dim - 1),\n",
    "        hidden_dim = config.graph_weights_hidden_dim,\n",
    "        n_layers = config.graph_weights_n_layers,\n",
    "        activation = config.graph_weights_activation,\n",
    "        slope = config.graph_weights_slope\n",
    "    ).to(torch.float64).to(config.device)\n",
    "\n",
    "    # Mutual Effects\n",
    "    mutual_effects = MLP(\n",
    "        input_dim = latent_dim,\n",
    "        # output_dim = latent_dim * (latent_dim - 1),\n",
    "        output_dim = 1,\n",
    "        hidden_dim = config.mutual_effects_hidden_dim,\n",
    "        n_layers = config.mutual_effects_n_layers,\n",
    "        activation = config.mutual_effects_activation,\n",
    "        slope = config.mutual_effects_slope\n",
    "    ).to(torch.float64).to(config.device)\n",
    "\n",
    "    # CIVAE model\n",
    "    civae = CIVAE(\n",
    "        data_encoder=data_encoder,\n",
    "        env_encoder=env_encoder,\n",
    "        latent_dim = latent_dim,\n",
    "        linear_prior_net = linear_prior,\n",
    "        env_encoder_linear_prior = env_encoder_linear_prior,\n",
    "        non_linear_prior_net = non_linear_prior,\n",
    "        env_encoder_non_linear_prior = env_encoder_non_linear_prior,\n",
    "        graph_weights_net = graph_weights,\n",
    "        mutual_effects_net = mutual_effects,\n",
    "        hidden_dim = config.civae_hidden_dim,\n",
    "        n_layers = config.civae_n_layers,\n",
    "        activation = config.civae_activation,\n",
    "        slope = config.civae_slope\n",
    "    ).to(torch.float64).to(config.device)\n",
    "\n",
    "    return civae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "5bf73274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1788db4130>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import yaml\n",
    "import os \n",
    "def dict2namespace(config):\n",
    "    namespace = argparse.Namespace()\n",
    "    for key, value in config.items():\n",
    "        if isinstance(value, dict):\n",
    "            new_value = dict2namespace(value)\n",
    "        else:\n",
    "            new_value = value\n",
    "        setattr(namespace, key, new_value)\n",
    "    return namespace\n",
    "with open(os.path.join('./configs', \"civae.yaml\"), 'r') as f:\n",
    "    # print(args.config)\n",
    "    # print(r)\n",
    "    # import pdb;pdb.set_trace()  \n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "config = dict2namespace(config)\n",
    "config.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# print(new_config)\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "21f9d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(10, 2, 4, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "10082f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./run/datasets/u_nl.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls \"./run/datasets/u_nl.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "81c43033",
   "metadata": {},
   "outputs": [],
   "source": [
    "U = np.load(f\"./run/datasets/u_nl.npy\")\n",
    "U_torch = torch.tensor(U).to(\"cuda:0\")\n",
    "U_torch = U_torch[:10, :]\n",
    "weights = model.weight_matrix_2D(U_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "5df25cb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[269], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(weigths_processed\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(weigths_processed\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m----> 6\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m==\u001b[39mj \u001b[38;5;129;01mor\u001b[39;00m weigths_processed[j, i]\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      7\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m weights[i, j] \u001b[38;5;241m>\u001b[39m weights[j, i]:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "weigths_processed = torch.zeros_like(weights)\n",
    "processed = [np.(weights)]\n",
    "\n",
    "for i in range(weigths_processed.shape[0]):\n",
    "    for j in range(weigths_processed.shape[1]):\n",
    "        if i==j or weigths_processed[j, i]!=0:\n",
    "            continue\n",
    "        if weights[i, j] > weights[j, i]:\n",
    "            weigths_processed[j, i] = 0\n",
    "        else:\n",
    "            weigths_processed[i, j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06554a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "6f098cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2000, 3.3563], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "\n",
    "print(U_torch[index, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "5b81f05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000, -94.4720,  33.0693, -79.5308],\n",
       "        [ 20.0107,   0.0000, -28.7187,  82.9653],\n",
       "        [  4.1322,  68.1637,   0.0000,  96.3725],\n",
       "        [-22.1382, -94.3256,  26.8252,   0.0000]], device='cuda:0',\n",
       "       dtype=torch.float64, grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "96825a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6000, 2), numpy.ndarray)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape, type(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af99708e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
